import sys
import os
from dataclasses import dataclass
from datetime import datetime, date
from typing import List, Optional, Dict
from src.lab08.models import Pervoxod
from src.lab08.serialize import * #students_from_json, students_to_json, print_students_info
import argparse
import csv
import re
from pathlib import Path
from src.lab05.csv_xlsx import *
from src.lab05.json_csv import *

class Group:
    def __init__(self, debri: str):
        self.path = Path(debri)
        if not self.path.exists():
            self.path.parent.mkdir(parents=True, exist_ok=True) 
            with open(self.path, 'w', encoding='utf-8', newline= '') as f:
                writer = csv.DictWriter(f, fieldnames=['fio','birth','group','gpa'])
                writer.writeheader()
            

    def _read_all(self):
        tolpa = []
        try:
            with open(self.path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for x in reader:
                    tolpa.append(x)
        except Exception:
            print('–û—à–∏–±–æ—á–∫–∞ –≤—ã—à–ª–∞')
            return []
        return tolpa            
    

    def _write_all(self, tolpa: List[Dict]):
        
        print(f"\n –í—ã–∑—ã–≤–∞—é_write_all:")
        print(f"   –§–∞–π–ª: {self.path.absolute()}")
        print(f"   –°—Ç—Ä–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏: {len(tolpa)}")
    
        try:
            self.path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.path, 'w', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=['fio', 'birth', 'group', 'gpa'])
                writer.writeheader()
                writer.writerows(tolpa)
        
            print(f"–ü–æ–ª—É—á–∏–ª–æ—Å—å")
        
        
            print(f"\n –ß–µ–∫:")
            with open(self.path, 'r', encoding='utf-8') as f:
                content = f.read()
                print(content)
        
        except Exception as e:
            print(f" –§–∏–≥–Ω—è –∫–∞–∫–∞—è-—Ç–æ: {e}")
            import traceback
            traceback.print_exc()
        
    def list(self) -> List[Pervoxod]:
        rows = self._read_all()
        tolpa = []
        for x in rows:
            try:
                if 'gpa' in x:
                    try:
                        x['gpa'] = float(x['gpa'])
                    except ValueError:
                        x['gpa'] = 0.0
                chui = Pervoxod.from_dict(x)
                tolpa.append(chui)
            except Exception:
                return ValueError
                continue
        return tolpa    

    def add(self, chui: Pervoxod):
        rows = self._read_all()
        for x in rows:
            if x['fio'] == chui.fio:
                print(f'–•–∞—Ç–∞ –Ω–µ —Ä–µ–∑–∏–Ω–æ–≤–∞—è')
                return
        new_row = {
            'fio': chui.fio,
            'birth': chui.birth,
            'group': chui.group,
            'gpa': str(chui.gpa)
        }
        rows.append(new_row)
        self._write_all(rows)
        print(f'–ü–∏—Ö–Ω—É–ª, –¥–∞')

    def find(self, podstr: str) -> List[Pervoxod]:
        rows = self._read_all()
        find_rows = [r for r in rows if podstr.lower() in r['fio'].lower()]
        found_studs = []
        for x in find_rows:
            try:
                if 'gpa' in x:
                    try:
                        x['gpa'] = float(x['gpa'])
                    except ValueError:
                        x['gpa'] = 0.0    
                chui = Pervoxod.from_dict(x)
                found_studs.append(chui)  
            except Exception:
                return ValueError
                continue
        return found_studs

    def remove(self, fio: str) -> bool:
        rows = self._read_all()
        stacoun = len(rows)
        fio_normalized = ' '.join(fio.strip().split()).lower()
        rows = [
            r for r in rows
             if ' '.join(r['fio'].strip().split()).lower() != fio_normalized
             ]

        if len(rows) < stacoun:
            self._write_all(rows)
            print(f'–í —Ç–æ–ø–∫—É —ç—Ç–æ–≥–æ {fio}')
            return True
        else:
            print(f'–ù–µ—Ç —Ç–∞–∫–∏—Ö')
            return False


    def update(self, fio: str, **fields):
        print(f" –ò—â—É —ç—Ç–æ–≥–æ –¥–æ–±—Ä—è–∫–∞ '{fio}'")
        print(f"   –ü–æ–ª—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {fields}")
    
        rows = self._read_all()
    
        if not rows:
            print("–ù–∏–æ–≥–æ –Ω–µ–º–∞—ç")
            return
    
        print(f" –°—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ: {len(rows)}")
    
        updated = False
        found_index = -1
    
        
        for i, row in enumerate(rows):
            print(f"   –ü—Ä–æ–≤–µ—Ä–∫–∞ {i+1}: '{row['fio']}' == '{fio}'")
            if row['fio'] == fio:
                found_index = i
                print(f"–ù–∞—à–µ–ª –Ω–∞ —Å—Ç—Ä–æ–∫–µ {i+1}!")
                break
    
        if found_index == -1:
            print(f"–ß—É–≤–∞–∫ '{fio}' –ø–æ—Ç–µ—Ä—è–ª—Å—è")
            print("\n –í—Å–µ–≥–æ:")
            for i, row in enumerate(rows):
                print(f"   {i+1}. '{row['fio']}'")
            return
    
    
        old_data = rows[found_index].copy()
    
         
        if 'new_fio' in fields:
            rows[found_index]['fio'] = fields['new_fio']
            print(f"–û–±–Ω—É–ª–∏–ª–∏: '{old_data['fio']}' ‚Üí '{fields['new_fio']}'")
            
            del fields['new_fio']
    
    
        for field, value in fields.items():
            if field in rows[found_index]:
                
                if field == 'gpa':
                    rows[found_index][field] = str(value)
                else:
                     rows[found_index][field] = value
            
                print(f"‚úèÔ∏è  {field}: '{old_data.get(field, 'N/A')}' ‚Üí '{value}'")
    
        updated = True
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        if updated:
            print(f"\n –©–∞ –≤—Å–µ –±—É–¥–µ—Ç")
            print(f"   –§–∞–π–ª: {self.path}")
        
        # –ü–æ–∫–∞–∂–µ–º —á—Ç–æ –±—É–¥–µ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
            print(f"\n –¢–µ–ø–µ—Ä—å –≤–æ—Ç —Ç–∞–∫:")
            for i, row in enumerate(rows):
                if i == found_index:
                    print(f"   ‚Üí {i+1}. {row['fio']} [–û–±–Ω—É–ª–µ–Ω]")
                else:
                    print(f"   {i+1}. {row['fio']}")
        
        # –í–´–ó–´–í–ê–ï–ú –°–û–•–†–ê–ù–ï–ù–ò–ï
            self._write_all(rows)
            print(f"–ì–æ—Ç–æ–≤–æ")
        else:
            print(f"–§–∏–≥–Ω—è –∫–∞–∫–∞—è-—Ç–æ, –Ω–∏—á–µ–≥–æ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å")

    def stats(self) -> Dict:
        tolpa = self.list()

        if not tolpa:
            return f'–ó–¥–µ—Å—å –ø—É—Å—Ç–æ'

        stats = {
            '–í—Å–µ–≥–æ': len(tolpa),
            '–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª': sum(s.gpa for s in tolpa) / len(tolpa),
            '–°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç': sum(s.age() for s in tolpa) / len(tolpa),
            '–ì—Ä—É–ø–ø—ã': sorted(set(s.group for s in tolpa)),
            'The Best—ã': sum(1 for s in tolpa if s.gpa >= 4.5),
            '–ù–æ—Ä–º–∏—Å—ã': sum(1 for s in tolpa if s.gpa >= 3.5 and s.gpa < 4.5),
        }   

        return stats

    def show_girls(self):
        tolpa = self.list()
        
        if not tolpa:
            print('–í –æ–∫–æ–ª–æ—Ç–∫–µ')
            return
        
        for i, chui in enumerate(tolpa, 1):
            print(f'\n#{i}: {chui.fio}')
            print(f'–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è: {chui.birth}')
            print(f'–í–æ–∑—Ä–∞—Å—Ç: {chui.age()}')
            print(f'–ì—Ä—É–ø–ø–∞: {chui.group}')
            print(f'–ë–∞–ª–ª: {chui.gpa}')



def kava():
    banga = argparse.ArgumentParser(
        description='–†–∞–±–æ—Ç–∞ —Å–æ —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏: JSON, CSV, Group',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  # –†–∞–±–æ—Ç–∞ —Å JSON
  %(prog)s json --mode save --output students.json --sample
  %(prog)s json --mode load --input students.json
  
  # –†–∞–±–æ—Ç–∞ —Å CSV (Group)
  %(prog)s csv --file students.csv --action list
  %(prog)s csv --file students.csv --action add --fio "–ò–≤–∞–Ω–æ–≤" --birth "2005-03-15" --group "SE-01" --gpa 4.5
  
  # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
  %(prog)s convert --from students.csv --to students.json
  %(prog)s convert --from students.json --to students.csv
        """
    )
    

    subparsers = banga.add_subparsers(
        title="–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã",
        dest="command",
        help="–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"
    )
    
    
    parser_json = subparsers.add_parser('json', help='–†–∞–±–æ—Ç–∞ —Å JSON —Ñ–∞–π–ª–∞–º–∏')
    parser_json.add_argument('--mode', type=str, required=True,
                             choices=['save', 'load'],
                             help='save: —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å, load: –∑–∞–≥—Ä—É–∑–∏—Ç—å')
    parser_json.add_argument('--input', type=str, help='–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª')
    parser_json.add_argument('--output', type=str, help='–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª')
    parser_json.add_argument('--sample', action='store_true',
                             help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤')
    
    
    parser_csv = subparsers.add_parser('csv', help='–†–∞–±–æ—Ç–∞ —Å CSV —Ñ–∞–π–ª–∞–º–∏ (Group)')
    parser_csv.add_argument('--file', type=str, required=True,
                            help='CSV —Ñ–∞–π–ª –≥—Ä—É–ø–ø—ã')
    parser_csv.add_argument('--action', type=str, required=True,
                            choices=['list', 'add', 'find', 'remove', 'update', 'stats'],
                            help='–î–µ–π—Å—Ç–≤–∏–µ —Å –≥—Ä—É–ø–ø–æ–π')
    parser_csv.add_argument('--fio', type=str, help='–§–ò–û —Å—Ç—É–¥–µ–Ω—Ç–∞')
    parser_csv.add_argument('--birth', type=str, help='–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è (YYYY-MM-DD)')
    parser_csv.add_argument('--group', type=str, help='–ì—Ä—É–ø–ø–∞')
    parser_csv.add_argument('--gpa', type=float, help='–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª (0-5)')
    parser_csv.add_argument('--search', type=str, help='–°—Ç—Ä–æ–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–¥–ª—è find)')
    parser_csv.add_argument('--new-fio', type=str, help='–ù–æ–≤–æ–µ –§–ò–û (–¥–ª—è update)')
    parser_csv.add_argument('--new-gpa', type=float, help='–ù–æ–≤—ã–π —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª (–¥–ª—è update)')
    
    
    parser_convert = subparsers.add_parser('convert', help='–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏')
    parser_convert.add_argument('--from', type=str, required=True, dest='from_file',
                                help='–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª')
    parser_convert.add_argument('--to', type=str, required=True,
                                help='–¶–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª')
    
    chaki = banga.parse_args()
    

    if not chaki.command:
        banga.print_help()
        return
    
    
    if chaki.command == 'json':
        if chaki.mode == 'save':
            if chaki.sample and chaki.output:
                students = [
                    Pervoxod("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "2005-03-15", "SE-01", 4.8),
                    Pervoxod("–ü–µ—Ç—Ä–æ–≤–∞ –ê–Ω–Ω–∞ –°–µ—Ä–≥–µ–µ–≤–Ω–∞", "2004-11-30", "SE-02", 3.5),
                    Pervoxod("–°–∏–¥–æ—Ä–æ–≤ –ê–ª–µ–∫—Å–µ–π –ü–µ—Ç—Ä–æ–≤–∏—á", "2005-07-20", "SE-01", 2.9),
                    Pervoxod("–ö—É–∑–Ω–µ—Ü–æ–≤–∞ –ú–∞—Ä–∏—è –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–Ω–∞", "2004-05-10", "SE-03", 0.0)
                ]
                students_to_json(students, chaki.output)
                print(f"–ó–∞–Ω–µ—Å–ª–∏ {len(students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ {chaki.output}")
            elif not chaki.sample:
                print(" --sample!!!!!")
            elif not chaki.output:
                print("--output !!!!!!")
        
        elif chaki.mode == 'load':
            if chaki.input:
                students = students_from_json(chaki.input)
                print_students_info(students, chaki.input)
            else:
                print("–ö–∞–∫–æ–≤ –í–∞—à --input —Ñ–∞–π–ª")
    
    
    elif chaki.command == 'csv':
        if not chaki.file:
            print("–ì–¥–µ --file?")
            return
        
        group = Group(chaki.file)
        
        if chaki.action == 'list':
            students = group.list()
            if isinstance(students, list):
                if students:
                    print(f"\n –ù–∞—à–µ–ª {len(students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ —Ñ–∞–π–ª–µ {chaki.file}:")
                    for i, student in enumerate(students, 1):
                       print(f"\n#{i}: {student.fio}")
                       print(f"   –ì—Ä—É–ø–ø–∞: {student.group}")
                       print(f"   –í–æ–∑—Ä–∞—Å—Ç: {student.age()} –ª–µ—Ç")
                       print(f"   –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: {student.gpa}")
                else:
                    print(f"–§–∞–π–ª {chaki.file} —Ç—É–ø–æ–π –∏ –∏–¥–µ—Ç –Ω–∞—Ñ–∏–≥")
            else:
                print(f"–§–∏–≥–Ω—è –ø–æ–ª—É—á–∏–ª–∞—Å—å: —Ñ—É–Ω–∫—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ {type(students)} –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–∞")
                #print_students_info(students, chaki.file)
        
        elif chaki.action == 'add':
            if all([chaki.fio, chaki.birth, chaki.group, chaki.gpa]):
                try:
                    student = Pervoxod(chaki.fio, chaki.birth, chaki.group, chaki.gpa)
                    group.add(student)
                except Exception:
                    return ValueError
            else:
                print("–ó–∞–±—ã–ª–∏ –ø—Ä–æ: --fio, --birth, --group, --gpa")
        
        elif chaki.action == 'find':
            if chaki.search:
                students = group.find(chaki.search)
                if isinstance(students, list):
                    if students:
                        print(f"\n –ù–∞–π–¥–µ–Ω–æ {len(students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{chaki.search}':")
                        for student in students:
                            print(f"  ‚Ä¢ {student.fio} (–≥—Ä—É–ø–ø–∞: {student.group}, GPA: {student.gpa})")
                else:
                    print(f"–ü–æ –∑–∞–ø—Ä–æ—Å—É '{chaki.search}' –Ω–∏—á–µ –Ω–µ—Ç")
            else:
                print("--search –Ω–∞–¥–æ")
        
        elif chaki.action == 'remove':
            if chaki.fio:
                group.remove(chaki.fio)
            else:
                print("--fio —É–∫–∞–∑—ã–≤–µ—Ç—Å—è —á—Ç–æ–±—ã –∑–∞—Ç–µ—Ä–µ—Ç—å —á—É–≤–∞—á–∫–∞")
        
        elif chaki.action == 'update':
            if chaki.fio:
                fields = {}
                if chaki.new_fio:
                    fields['new_fio'] = chaki.new_fio
                if chaki.new_gpa:
                    fields['gpa'] = chaki.new_gpa
                if chaki.group:
                    fields['group'] = chaki.group
                if chaki.birth:
                    fields['birth'] = chaki.birth
                
                if fields:
                    group.update(chaki.fio, **fields)
                else:
                    print("–ö–∞–∫–∏–µ –ø–æ–ª—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: --new-fio, --new-gpa, --group, --birth")
            else:
                print("—É–∫–∞–∂–∏—Ç–µ --fio —Å—Ç—É–¥–µ–Ω—Ç–∞, –µ—Å–ª–∏ –æ–Ω —á–µ—Ç–æ —Å–º–µ–Ω–∏–ª")
        
        elif chaki.action == 'stats':
            stats = group.stats()
            print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ì–†–£–ü–ü–´ ({chaki.file}):")
            print(f"   –í—Å–µ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {stats['total']}")
            if stats['total'] > 0:
                print(f"   –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: {stats['avg_gpa']:.2f}")
                print(f"   –°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç: {stats['avg_age']:.1f} –ª–µ—Ç")
                print(f"   –ì—Ä—É–ø–ø—ã: {', '.join(stats['groups'])}")
    
    
    elif chaki.command == 'convert':
        from_ext = os.path.splitext(chaki.from_file)[1].lower()
        to_ext = os.path.splitext(chaki.to)[1].lower()
        
        if from_ext == '.csv' and to_ext == '.json':
            csv_2_json(chaki.from_file, chaki.to)
        elif from_ext == '.json' and to_ext == '.csv':
            json_2_csv(chaki.from_file, chaki.to)
        else:
            print(f"–¢—É—Ç —Ç–∞–∫ –Ω–µ—Ç—É: {from_ext} ‚Üí {to_ext}")
            print("   –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: CSV ‚Üî JSON")

if __name__ == '__main__':
    kava()